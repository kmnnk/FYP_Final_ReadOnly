{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from Asp_smth_funcs_opt import SAVGOL_smoothing, WT_smoothing, SNR_diff, plot_WT, plot_SAVGOL\n",
    "from Asp_baselinne_funcs_opt import als_baseline, polym_fitting_baseline\n",
    "import numpy\n",
    "import scipy.io\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import detrend\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "# from statsmodels.tsa.tsatools import detrend\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import pywt\n",
    "from math import log10, sqrt\n",
    "import time\n",
    "import pysptools\n",
    "from pysptools import distance\n",
    "import math\n",
    "import pandas as pd\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Asprin data\n",
    "# Construct the full path of the file \n",
    "file_path = os.path.join(os.getcwd(), 'Asprin.xlsx')\n",
    "\n",
    "# Read the Excel file which has the downloaded corrrect Asprin data into a pandas DataFrame\n",
    "wavelengths = pd.read_excel(file_path, usecols = 'A', header = None)\n",
    "wavelengths_arr = (wavelengths.values).flatten()\n",
    "\n",
    "intensity = pd.read_excel(file_path, usecols = 'B', header = None)\n",
    "intensity_arr = (intensity.values).flatten()\n",
    "\n",
    "fig, axs = plt.subplots(3)\n",
    "fig.suptitle('Vertically stacked subplots')\n",
    "axs[0].plot(wavelengths_arr, intensity_arr, lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding noise\n",
    "mu=0.0\n",
    "std = 0.70 * np.std(intensity_arr)\n",
    "def gaussian_noise(x,mu,std):\n",
    "    noise = np.random.normal(mu, std, size = x.shape)\n",
    "    x_noisy = x + noise\n",
    "    return x_noisy, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING THE WT AND SAVGOL SMOOTHING - can change the level of noise above (done for 0.6/0.7/0.8/0.9)\n",
    "true_signal_power = np.mean(np.abs(intensity_arr)**2)\n",
    "noise_power = np.mean(np.abs(generated_noise)**2)\n",
    "\n",
    "plot_WT(noisy_spec, intensity_arr, true_signal_power, noise_power)\n",
    "plot_SAVGOL(noisy_spec, intensity_arr, true_signal_power, noise_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking which wl and pO is best for savgol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_snr = -np.inf\n",
    "optimal_window_length = None\n",
    "\n",
    "true_signal_power = np.mean(np.abs(intensity_arr)**2)\n",
    "\n",
    "for i in range(100): #do this process over 100 diff random noise added spectra\n",
    "    noisy_spec, generated_noise = gaussian_noise(intensity_arr, mu, std)\n",
    "\n",
    "    noise_power = np.mean(np.abs(generated_noise)**2)\n",
    "\n",
    "    # Iterate over a range of polynomial orders\n",
    "    for pO in range(1, 9):\n",
    "    # Iterate over a range of window lengths\n",
    "        for wl in range(9, 151, 2):\n",
    "            # Skip if the polynomial order is greater than or equal to the window length\n",
    "            if pO >= wl:\n",
    "                continue\n",
    "            smthed_noise, _ = SAVGOL_smoothing(noisy_spec, intensity_arr, wl, pO)\n",
    "            \n",
    "            # Calculate the SNR for this window length\n",
    "            rel_snr, abs_snr = SNR_diff(true_signal_power, noise_power, smthed_noise)\n",
    "\n",
    "            # If this SNR is greater than the current maximum...\n",
    "            if rel_snr > max_snr:\n",
    "                    # Update the maximum SNR and optimal window length\n",
    "                max_snr = rel_snr\n",
    "                optimal_pO = pO\n",
    "                optimal_window_length = wl\n",
    "\n",
    "# Print the optimal window length\n",
    "print(f\"The optimal wl and pO is {optimal_window_length, optimal_pO}\")\n",
    "\n",
    "# After the loop, plot the smoothed spectra\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # for (poly_order, window_l), spectrum in smoothed_spectra.items():\n",
    "    #     print(f'Poly order: {poly_order}, Window length: {window_l}, Spectrum: {spectrum}') # Modify this line with what being varied\n",
    "    #     plt.plot(spectrum, label=f'Poly order: {poly_order}, Window length: {window_l}')\n",
    "    # plt.title('Smoothed spectra for different parameters')\n",
    "    # plt.xlabel('Wavelength index')\n",
    "    # plt.ylabel('Intensity')\n",
    "    # plt.legend()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = wavelengths_arr\n",
    "# y = -10 * x + 5 + np.random.normal(0, 1, len(x)) # arbitary linear trend added\n",
    "#\n",
    "# noisy_trend_spec = noisy_spec + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify smth should come first\n",
    "percdiff_detrsmth = []\n",
    "percdiff_smthdetr =[]\n",
    "for i in range(5):\n",
    "    noisy_spec, generated_noise = gaussian_noise(intensity_arr, mu, std)\n",
    "    x = wavelengths_arr\n",
    "    y = -10 * x + 5 + np.random.normal(0, 1, len(x))  # arbitary linear trend added\n",
    "    noisy_trend_spec = noisy_spec + y\n",
    "\n",
    "    #SmthDetr\n",
    "    smth1 = savgol_filter(noisy_trend_spec, 11,3)\n",
    "    detr1 = detrend(smth1, type = 'linear')\n",
    "\n",
    "    #DetrSmth\n",
    "    detr2 = detrend(noisy_trend_spec, type = 'linear')\n",
    "    smth2 = savgol_filter(detr2, 11,3)\n",
    "\n",
    "    perct_diff1 = 0\n",
    "    for value1, value2 in zip(intensity_arr, detr1):\n",
    "        if value1 == 0:\n",
    "            pass\n",
    "        else:\n",
    "            perct_diff1 = abs((value1 - value2) / value1) * 100\n",
    "            perct_diff1 += perct_diff1\n",
    "    percdiff_smthdetr.append(np.mean(perct_diff1))\n",
    "\n",
    "    perct_diff2 = 0\n",
    "    for value3, value4 in zip(intensity_arr, smth2):\n",
    "        if value3 == 0:\n",
    "            pass\n",
    "        else:\n",
    "            perct_diff2 = abs((value3 - value4) / value3) * 100\n",
    "            perct_diff2 += perct_diff2\n",
    "    percdiff_detrsmth.append(np.mean(perct_diff2))\n",
    "\n",
    "\n",
    "data_dict1 = {'trials': percdiff_detrsmth\n",
    "             }\n",
    "\n",
    "data_dict2 = {'trials': percdiff_smthdetr\n",
    "             }\n",
    "\n",
    "df1 = pd.DataFrame(data_dict1)\n",
    "df1.to_csv('detrsmth.csv')\n",
    "\n",
    "df2 = pd.DataFrame(data_dict2)\n",
    "df2.to_csv('smthdetr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding baseline to Asprin\n",
    "\n",
    "noisy_spectrum = noisy_spec + 10000  #all you need to do to generate a baseline\n",
    "\n",
    "# polym_fitting_baseline(4, wavelengths_arr, noisy_spec)\n",
    "perc_diff_all_asymm = []\n",
    "for smooth in [10000, 100000, 1000000, 10000000, 100000000, 1000000000]:\n",
    "    perc_diff_asymm = []\n",
    "    for asymm in np.arange(0, 1.01, 0.05):\n",
    "        baselined_spec = als_baseline(noisy_spectrum, smooth, asymm) # start at asymm = 0.5, tested both sides, more positive wasnt good, so went closer ot 0\n",
    "        perct_diff = 0\n",
    "        for value1, value2 in zip(noisy_spec, baselined_spec):\n",
    "            if value1 == 0:\n",
    "                pass\n",
    "            else:\n",
    "                perct_diff = abs((value1 - value2) / value1) * 100\n",
    "                perct_diff += perct_diff\n",
    "                #perct_diff = np.mean(np.array(abs((value1 - value2) / value1) * 100))\n",
    "        perc_diff_asymm.append(np.mean(perct_diff))\n",
    "    perc_diff_all_asymm.append(perc_diff_asymm)\n",
    "\n",
    "data_dict = {'asym value': np.arange(0, 1.01, 0.05),\n",
    "             '10000': perc_diff_all_asymm[0],\n",
    "             '100000': perc_diff_all_asymm[1],\n",
    "             '1000000': perc_diff_all_asymm[2],\n",
    "             '10000000': perc_diff_all_asymm[3],\n",
    "             '100000000': perc_diff_all_asymm[4],\n",
    "             '1000000000': perc_diff_all_asymm[5],\n",
    "             }\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('noise_als_baseline.csv')\n",
    "\n",
    "print(perc_diff_all_asymm)\n",
    "min_value = float('inf')  # Initialise to positive infinity\n",
    "min_indices = (-1, -1, -1)  # Initialise with invalid indices\n",
    "\n",
    "for i, list in enumerate(perc_diff_all_asymm):\n",
    "    for j, value in enumerate(list):\n",
    "        if value < min_value:\n",
    "            min_value = value\n",
    "            min_indices = (i, j)\n",
    "\n",
    "\n",
    "#PRINT MIN PERCRENTAGED DIFF\n",
    "print(f\"Minimum value={min_value} is at location={min_indices}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
